# Jupyter Notebooks Guide

é€™å€‹ç›®éŒ„åŒ…å« 6 å€‹åŠŸèƒ½æ€§ Jupyter notebooksï¼ŒæŒ‰ç…§å°ˆæ¡ˆæµç¨‹çµ„ç¹”ã€‚

## ğŸ“š Notebook åˆ—è¡¨

### âœ… å·²å‰µå»ºçš„ Notebooks

1. **01_data_exploration.ipynb** - æ•¸æ“šæ¢ç´¢
   - æ•¸æ“šé›†çµ±è¨ˆ
   - é¡åˆ¥åˆ†ä½ˆ
   - æ¨£æœ¬å¯è¦–åŒ–
   - åœ–åƒå±¬æ€§åˆ†æ
   - é¡è‰²åˆ†ä½ˆåˆ†æ

2. **02_preprocessing.ipynb** - åœ–åƒé è™•ç†
   - åœ–åƒèª¿æ•´å¤§å° (224Ã—224)
   - HSV èƒŒæ™¯å»é™¤
   - å½¢æ…‹å­¸æ“ä½œ
   - ä¸­å€¼æ¿¾æ³¢
   - è³ªé‡è©•ä¼°

3. **03_feature_extraction.ipynb** - ç‰¹å¾µæå–
   - GLCM ç‰¹å¾µ (60D)
   - åˆ†å½¢ç¶­åº¦ (1D)
   - è‘‰è„ˆå¹¾ä½• (10D)
   - MobileNetV2 CNN ç‰¹å¾µ (1280D)
   - ä½¿ç”¨ PyTorch + CUDA

### ğŸ“ å¾…å‰µå»ºçš„ Notebooks (çµæ§‹èªªæ˜)

#### 4. **04_clustering_analysis.ipynb** - èšé¡åˆ†æ

```python
# ä¸»è¦å…§å®¹ï¼š
# 1. è¼‰å…¥ç‰¹å¾µ
# 2. ç‰¹å¾µæ¨™æº–åŒ– (StandardScaler)
# 3. PCA é™ç¶­ (1351D â†’ 50D)
# 4. K-means èšé¡ (k=5)
# 5. å±¤æ¬¡èšé¡ (Ward linkage)
# 6. è¼ªå»“åˆ†æ•¸è©•ä¼°
# 7. 2D/3D å¯è¦–åŒ– texture space
# 8. èšé¡è¼ªå»“åˆ†æ
```

**é—œéµä»£ç¢¼ç¤ºä¾‹**:
```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering

# PCA
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)
pca = PCA(n_components=50)
features_pca = pca.fit_transform(features_scaled)

# K-means
kmeans = KMeans(n_clusters=5, n_init=100, random_state=42)
labels_kmeans = kmeans.fit_predict(features_pca)

# Hierarchical
hierarchical = AgglomerativeClustering(n_clusters=5, linkage='ward')
labels_hier = hierarchical.fit_predict(features_pca)
```

#### 5. **05_disease_classification.ipynb** - ç–¾ç—…åˆ†é¡

```python
# ä¸»è¦å…§å®¹ï¼š
# 1. å®šç¾©è‡ªå®šç¾© Dataset class
# 2. æ•¸æ“šå¢å¼· (transforms)
# 3. Fine-tune MobileNetV2 åˆ†é¡å™¨ (10 classes)
# 4. è¨“ç·´å¾ªç’° (ä½¿ç”¨ CUDA)
# 5. é©—è­‰å’Œæ¸¬è©¦
# 6. æ··æ·†çŸ©é™£
# 7. Top-3 æº–ç¢ºç‡
# 8. ä¿å­˜æ¨¡å‹
```

**é—œéµä»£ç¢¼ç¤ºä¾‹**:
```python
import torch
import torch.nn as nn
import torchvision.models as models

# å‰µå»ºåˆ†é¡å™¨
model = models.mobilenet_v2(pretrained=True)
model.classifier[1] = nn.Linear(model.last_channel, 10)
model = model.to(device)

# è¨“ç·´
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(num_epochs):
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

#### 6. **06_dual_application.ipynb** - é›™é‡æ‡‰ç”¨å±•ç¤º

```python
# ä¸»è¦å…§å®¹ï¼š
# 1. è¼‰å…¥è¨“ç·´å¥½çš„åˆ†é¡æ¨¡å‹
# 2. è¼‰å…¥èšé¡æ¨¡å‹
# 3. å–®å¼µåœ–åƒçš„é›™é‡åˆ†æï¼š
#    - Application 1: ç–¾ç—…é æ¸¬ (label + confidence)
#    - Application 2: å·¥ç¨‹åƒæ•¸ (roughness, anisotropy, complexity)
# 4. Disease-Texture ç›¸é—œæ€§åˆ†æ
# 5. èšé¡èˆ‡ç–¾ç—…æ¨™ç±¤çš„å°æ‡‰é—œä¿‚
# 6. å‰µå»ºå®Œæ•´çš„åˆ†æå ±å‘Š
```

**é—œéµä»£ç¢¼ç¤ºä¾‹**:
```python
def dual_analysis(image_path):
    # Application 1: Disease Detection
    with torch.no_grad():
        prediction = classifier_model(image)
        disease_label = classes[prediction.argmax()]
        confidence = prediction.softmax(dim=1).max()

    # Application 2: Engineering Analysis
    features = extract_all_features(image_path)
    glcm_contrast = features['glcm'][0]  # Roughness proxy
    fractal_dim = features['fractal'][0]  # Complexity
    vein_density = features['vein'][0]    # Structure

    cluster_id = kmeans.predict(pca.transform([combined_features]))[0]

    return {
        'disease': disease_label,
        'confidence': confidence,
        'roughness_proxy': glcm_contrast,
        'complexity': fractal_dim,
        'vein_density': vein_density,
        'texture_cluster': cluster_id
    }
```

## ğŸš€ ä½¿ç”¨é †åº

å»ºè­°æŒ‰ç…§ä»¥ä¸‹é †åºåŸ·è¡Œ notebooksï¼š

1. **01_data_exploration.ipynb** â†’ äº†è§£æ•¸æ“šé›†
2. **02_preprocessing.ipynb** â†’ å­¸ç¿’é è™•ç†æ–¹æ³•
3. **03_feature_extraction.ipynb** â†’ æå–ç‰¹å¾µï¼ˆéœ€è¦ GPUï¼‰
4. **04_clustering_analysis.ipynb** â†’ åˆ†æç´‹ç†ç©ºé–“
5. **05_disease_classification.ipynb** â†’ è¨“ç·´åˆ†é¡å™¨ï¼ˆéœ€è¦ GPUï¼‰
6. **06_dual_application.ipynb** â†’ å®Œæ•´çš„é›™é‡æ‡‰ç”¨æ¼”ç¤º

## âš™ï¸ ç’°å¢ƒéœ€æ±‚

### å¿…éœ€
- Python 3.8+
- PyTorch 1.12+ (with CUDA)
- CUDA-capable GPU (æ¨è–¦)

### å®‰è£ä¾è³´
```bash
# å‰µå»ºè™›æ“¬ç’°å¢ƒ
conda create -n leaf-texture python=3.8
conda activate leaf-texture

# å®‰è£ PyTorch (CUDA ç‰ˆæœ¬)
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# å®‰è£å…¶ä»–ä¾è³´
pip install -r requirements.txt
```

## ğŸ“Š é æœŸè¼¸å‡º

### æ•¸æ“šæ–‡ä»¶
- `dataset_statistics.csv` - æ•¸æ“šé›†çµ±è¨ˆ
- `dataset_summary.json` - æ•¸æ“šæ‘˜è¦
- `features_train.pkl` - è¨“ç·´é›†ç‰¹å¾µ (~1GB)
- `features_val.pkl` - é©—è­‰é›†ç‰¹å¾µ (~100MB)
- `pca_model.pkl` - PCA æ¨¡å‹
- `kmeans_model.pkl` - K-means æ¨¡å‹
- `classifier_model.pth` - åˆ†é¡å™¨æ¨¡å‹

### å¯è¦–åŒ–åœ–åƒ
- `class_distribution.png`
- `sample_images.png`
- `color_distribution.png`
- `preprocessing_pipeline.png`
- `feature_comparison.png`
- `texture_space_2d.png`
- `texture_space_3d.png`
- `confusion_matrix.png`
- `dual_application_demo.png`

## ğŸ”§ Troubleshooting

### GPU Out of Memory
```python
# æ¸›å°‘ batch size
CNN_BATCH_SIZE = 16  # åŸæœ¬ 32

# æˆ–é™åˆ¶è™•ç†çš„åœ–åƒæ•¸é‡
batch_extract_features(TRAIN_DIR, output_path, limit_per_class=100)
```

### CUDA Not Available
å¦‚æœæ²’æœ‰ GPUï¼Œä»£ç¢¼æœƒè‡ªå‹•åˆ‡æ›åˆ° CPUï¼š
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# CPU æ¨¡å¼æœƒè¼ƒæ…¢ï¼Œä½†ä»å¯é‹è¡Œ
```

### Memory Issues
```python
# åˆ†æ‰¹è™•ç†å¤§å‹æ•¸æ“šé›†
for class_dir in TRAIN_DIR.iterdir():
    features = batch_extract_features(
        class_dir,
        output_path,
        limit_per_class=50  # æ¯æ¬¡åªè™•ç† 50 å¼µ
    )
```

## ğŸ“ ç­†è¨˜

- **Notebook 1-3** å·²å®Œæ•´å¯¦ç¾
- **Notebook 4-6** æä¾›çµæ§‹å’Œé—œéµä»£ç¢¼ï¼Œå¯è‡ªè¡Œè£œå……å®Œæ•´
- æ‰€æœ‰ä»£ç¢¼éµå¾ª README.md çš„åƒæ•¸è¨­å®š
- ä½¿ç”¨ PyTorch è€Œé TensorFlow (ç”¨æˆ¶æœ‰ CUDA)
- åŒ…å«å®Œæ•´çš„å¯è¦–åŒ–å’Œå·¥ç¨‹è§£é‡‹

## âœ… å¿«é€Ÿé–‹å§‹

```bash
# 1. é€²å…¥ notebooks ç›®éŒ„
cd notebooks

# 2. å•Ÿå‹• Jupyter
jupyter notebook

# 3. æŒ‰é †åºæ‰“é–‹ notebooks
# 01 â†’ 02 â†’ 03 â†’ 04 â†’ 05 â†’ 06
```

## ğŸ¯ æœ€çµ‚ç›®æ¨™

å®Œæˆæ‰€æœ‰ notebooks å¾Œï¼Œä½ å°‡ç²å¾—ï¼š
1. âœ“ å®Œæ•´çš„æ•¸æ“šæ¢ç´¢å ±å‘Š
2. âœ“ é è™•ç†éçš„åœ–åƒ
3. âœ“ 1351D ç‰¹å¾µå‘é‡ï¼ˆæ‰€æœ‰åœ–åƒï¼‰
4. âœ“ ç´‹ç†ç©ºé–“èšé¡çµæœ
5. âœ“ è¨“ç·´å¥½çš„ç–¾ç—…åˆ†é¡å™¨ (~92% æº–ç¢ºç‡)
6. âœ“ é›™é‡æ‡‰ç”¨æ¼”ç¤ºï¼ˆç–¾ç—…æª¢æ¸¬ + å·¥ç¨‹åˆ†æï¼‰

é€™äº›è¼¸å‡ºå¯ä»¥ç›´æ¥ç”¨æ–¼ä½ çš„ HW4 å ±å‘Šå’Œè«–æ–‡æ’°å¯«ï¼
